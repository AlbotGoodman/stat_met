{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the pipe flow data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will statistically explore the pipe flow data set and try to implement a predictive regression model. There are tried and trued modules for this but since they lack rigoruous statistical comparison I will write these from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from linear_regression import LinearRegression as lr\n",
    "\n",
    "data = pd.read_csv(\"../data/Small-diameter-flow.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffled = data.sample(frac=1, random_state=42)  # setting the seed for reproducibility\n",
    "\n",
    "train_indices = round(0.8 * len(data_shuffled))\n",
    "val_indices = round(0.25 * train_indices)\n",
    "test_indices = round(0.2 * len(data_shuffled))\n",
    "\n",
    "test_df = pd.DataFrame(data_shuffled[:test_indices])\n",
    "train_df = pd.DataFrame(data_shuffled[test_indices:])\n",
    "val_df = pd.DataFrame(train_df[:val_indices])\n",
    "train_df = pd.DataFrame(train_df[val_indices:])\n",
    "\n",
    "X_train = np.column_stack([np.ones(len(train_df)), train_df[\"Kinematic\"], train_df[\"Geometric\"], train_df[\"Inertial\"], train_df[\"Observer\"]])\n",
    "y_train = train_df[\"Flow\"]\n",
    "\n",
    "X_val = np.column_stack([np.ones(len(val_df)), val_df[\"Kinematic\"], val_df[\"Geometric\"], val_df[\"Inertial\"], val_df[\"Observer\"]])\n",
    "y_val = val_df[\"Flow\"]\n",
    "\n",
    "X_test = np.column_stack([np.ones(len(test_df)), test_df[\"Kinematic\"], test_df[\"Geometric\"], test_df[\"Inertial\"], test_df[\"Observer\"]])\n",
    "y_test = test_df[\"Flow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As necessary for a predictive model I split the available data into set. I've used the 80/20 rule of thumb and used 80 % of the data towards training and 20 % to testing. I did this since it is common practice in machine learning to have enough data to meaningfully train the model but still keep a relevant portion for testing. I have also split the training data further into a validation set as well. Splitting that into 75/25 I have ensured that the size of the validation set match the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 118\n",
      "Validation set size: 40\n",
      "Test set size: 40\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = lr.standardise(X_train, True)\n",
    "y_train = lr.standardise(y_train, False)\n",
    "\n",
    "X_val = lr.standardise(X_val, True)\n",
    "y_val = lr.standardise(y_val, False)\n",
    "\n",
    "X_test = lr.standardise(X_test, True)\n",
    "y_test = lr.standardise(y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I do here is to set the mean and standard deviation of each feature to practically zero and one, respectively. I do so to make sure that all features are on the same scale. That would perhaps not be necessary in this case, let's look at the minimum and maximum values of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow\n",
      "Max value: -11.095608576515785\n",
      "Min value: -17.04768667660043\n",
      "\n",
      "Kinematic\n",
      "Max value: 1.242506468328179\n",
      "Min value: -0.6988778552689303\n",
      "\n",
      "Geometric\n",
      "Max value: -5.069475794119189\n",
      "Min value: -6.8963265831585145\n",
      "\n",
      "Inertial\n",
      "Max value: -11.583284099183867\n",
      "Min value: -14.332156294806332\n",
      "\n",
      "Observer\n",
      "Max value: 1.0\n",
      "Min value: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in data.columns:\n",
    "    print(f\"{feature}\\nMax value: {data[feature].max()}\\nMin value: {data[feature].min()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values differ from each other but not in extremes. Still, the max value of inertial is ten times that of kinematic. Therefore I have chosen to standardise the data to more fairly evaluate them. That is also why I have not normalised the data, as to keep the shape of the data.   \n",
    "\n",
    "What expanded on is to fully implement the standardisation function in the LinearRegression class. Then I could do the standardising in other methods and also save the mean and standard deviation from the training set to use in the other sets to avoid data leakage and always evaluate against the training values. Keep this in mind as we digest the significance, relevance and estimations later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance of f-statistic: 3.93e-143\n",
      "Significance of t-statistic for ...\n",
      "... Kinematic: 2.68e-45\n",
      "... Geometric: 1.29e-157\n",
      "... Inertial:  7.37e-246\n",
      "... Observer:  5.71e-161\n",
      "\n",
      "Relevance (R²): 9.97e-01\n",
      "\n",
      "Training set estimations ...\n",
      "... RSE:  5.39e-02\n",
      "... MSE:  2.78e-03\n",
      "... RMSE: 5.28e-02\n",
      "\n",
      "Validation set estimations ...\n",
      "... RSE:  5.66e-02\n",
      "... MSE:  2.81e-03\n",
      "... RMSE: 5.30e-02\n",
      "\n",
      "Testing set estimations ...\n",
      "... RSE:  5.22e-02\n",
      "... MSE:  2.38e-03\n",
      "... RMSE: 4.88e-02\n",
      "\n",
      "Confidence intervals for each coefficient ...\n",
      "... β0: -0.0087 ± 0.0007 | Lower: -0.0094, Upper: -0.0079\n",
      "... β1: 0.3028 ± 0.0024 | Lower: 0.3004, Upper: 0.3051\n",
      "... β2: 1.1073 ± 0.0014 | Lower: 1.1058, Upper: 1.1087\n",
      "... β3: -0.4096 ± 0.0030 | Lower: -0.4126, Upper: -0.4066\n",
      "... β4: 0.0189 ± 0.0011 | Lower: 0.0178, Upper: 0.0200\n",
      "\n",
      "Correlation pairs ...\n",
      "... Kinematic - Geometric: 0.8688\n",
      "... Kinematic - Inertial: 0.9720\n",
      "... Kinematic - Observer: 0.1783\n",
      "... Geometric - Inertial: 0.9196\n",
      "... Geometric - Observer: 0.2242\n",
      "... Inertial - Observer: 0.1774\n"
     ]
    }
   ],
   "source": [
    "model = lr()\n",
    "model.fit(X_train, y_train)\n",
    "y_hat_val = model.predict(X_val)\n",
    "\n",
    "sig = model.significance(X_train, y_train)\n",
    "print(f\"Significance of f-statistic: {sig[\"f_pvalue\"]:.2e}\")\n",
    "print(f\"Significance of t-statistic for ...\\n... Kinematic: {sig[\"ti_pvalues\"][0]:.2e}\\n... Geometric: {sig[\"ti_pvalues\"][1]:.2e}\\n... Inertial:  {sig[\"ti_pvalues\"][2]:.2e}\\n... Observer:  {sig[\"ti_pvalues\"][3]:.2e}\")\n",
    "print()\n",
    "print(f\"Relevance (R²): {model.r_squared(X_train, y_train):.2e}\")\n",
    "print()\n",
    "\n",
    "train_rel = model.estimates(X_train, y_train)\n",
    "val_rel = model.estimates(X_val, y_val)\n",
    "test_rel = model.estimates(X_test, y_test)\n",
    "train_rel = {key: value.item() for key, value in train_rel.items()}\n",
    "val_rel = {key: value.item() for key, value in val_rel.items()}\n",
    "test_rel = {key: value.item() for key, value in test_rel.items()}\n",
    "print(f\"Training set estimations for ...\\n... RSE:  {train_rel[\"RSE\"]:.2e}\\n... MSE:  {train_rel[\"MSE\"]:.2e}\\n... RMSE: {train_rel[\"RMSE\"]:.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Validation set estimations for ...\\n... RSE:  {val_rel[\"RSE\"]:.2e}\\n... MSE:  {val_rel[\"MSE\"]:.2e}\\n... RMSE: {val_rel[\"RMSE\"]:.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Testing set estimations for ...\\n... RSE:  {test_rel[\"RSE\"]:.2e}\\n... MSE:  {test_rel[\"MSE\"]:.2e}\\n... RMSE: {test_rel[\"RMSE\"]:.2e}\")\n",
    "print()\n",
    "\n",
    "ci = model.confidence_intervals(X_train, y_train)\n",
    "print(\"Confidence intervals for each coefficient ...\")\n",
    "for i, margin in enumerate(ci):\n",
    "    print(f\"... β{i}: {model._b[i]:.4f} ± {margin:.4f} | Lower: {model._b[i] - margin:.4f}, Upper: {model._b[i] + margin:.4f}\")\n",
    "print()\n",
    "\n",
    "r = model.pearson(X_train)\n",
    "cols = [\"Kinematic\", \"Geometric\", \"Inertial\", \"Observer\"]\n",
    "print(\"Correlation pairs ...\")\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        print(f\"... {cols[i]} - {cols[j]}: {r[i, j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the output\n",
    "\n",
    "We can tell from the extremely low p-values that the significance of the regression as a whole and each parameter is highly significant. What that means is that the probability of the null hypothesis being true is very, very low. If there was no relationship between the model (or the features) the probability would instead have been high. All features contribute to predict flow values. There is however one parameter that sticks out and that is kinematic. It has the lowest (comparably) significance out of all. What could be interesting is to exclude that in another run and see what values we would get.  \n",
    "\n",
    "R² tells us that the model has an excellent fit. We can predict 99.7 % of the data using our dependant variables. Since we now know that the significance of those variables are also relevant we can conclude that the high result in R² is not just a fluke. However further analysis could be appropriate to investigate overfitting or if the relationship between the variables causes this.  \n",
    "\n",
    "Regarding estimates we have a few interesting results. Generally we would hope that the values would be lower in the validation and testing. Here they do not which could just be the result of the shuffled data but also the +not fully correct implementation of standardisation. Despite that though the intervals are not big which speaks in favour of a more stable model.  \n",
    "\n",
    "Speaking of narrow intervals, we can see the same in the confidence intervals. With our 95 % confidence level we can be 95 % sure that the true values would lie between these narrow intervals. Depending on the need of the regression model this could be either very good or not even functional. Typically scientific accuracy need slim margins while perhaps a commercial model more uncertainty would be accepted.  \n",
    "\n",
    "Lastly we look at the intervals. Immediately we find that all parameters correlate highly with each other, something we call multicollinearity. It means that ... and can lead to unreliable estimates on unseen data. Preferrably we would remove variables that show high correlation between each other or increase the data - which is not plausible in this case.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating observer bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of the observer is 5.71e-161 (on par with the geometric variable). This shows that the observer has an effect on the predicted flow. We can therefore reject the null hypothesis for the observer variable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "Spoiler alert: the data set has been collected by the teacher in this course. And as has been mentioned during lectures the reason that the relationship between the features is so strong is due to them being fundamental in fluid dynamics.  \n",
    "\n",
    "That is why our model can show such high values in R² and the estimations between sets be so static. However it has still been a challenge to correctly performing a \"statistical analysis\", meaning implementing tools to measure and evaluate the model.  \n",
    "\n",
    "I have also enjoyed the opportunity to try my hands on a predictive model and look forward to learning more about machine learning techniques.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
