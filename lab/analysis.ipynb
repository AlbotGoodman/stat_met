{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "class lr:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._d = None\n",
    "        self._n = None\n",
    "        self._con_lvl = 0.95\n",
    "        self.a = 1-self._con_lvl    # alpha\n",
    "        self.b = None\n",
    "\n",
    "    @property\n",
    "    def d(self):\n",
    "        return self._d\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def confidence_level(self):\n",
    "        return self._con_lvl\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.b = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "        self._d = len(self.b) - 1\n",
    "        self._n = y.shape[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.b\n",
    "\n",
    "    def variance(self, X, y):\n",
    "        SSE = np.sum(np.square(y - X @ self.b))\n",
    "        return SSE / (self._n - self._d - 1)\n",
    "\n",
    "    def standard_deviation(self, X, y):\n",
    "        var = self.variance(X, y)\n",
    "        return np.sqrt(var)\n",
    "\n",
    "    def significance(self, X, y):\n",
    "        var = self.variance(X, y)\n",
    "        std_dev = np.sqrt(var)\n",
    "        SSE = np.sum(np.square(y - X @ self.b))\n",
    "        SST = np.sum(np.square(y - np.mean(y)))\n",
    "        SSR = SST - SSE\n",
    "        f_stat = (SSR / self._d) / var\n",
    "        f_pvalue = stats.f.sf(f_stat, self._d, self._n - self._d - 1)\n",
    "        cov_matrix = np.linalg.pinv(X.T @ X) * var\n",
    "        ti_stat = [self.b[i] / (std_dev * np.sqrt(cov_matrix[i, i])) for i in range(self._d)]\n",
    "        ti_pvalues = [2 * min(stats.t.cdf(i, self._n - self._d - 1), stats.t.sf(i, self._n - self._d - 1)) for i in ti_stat]\n",
    "        return {\n",
    "            \"f_pvalue\": f_pvalue, \n",
    "            \"ti_pvalues\": ti_pvalues\n",
    "        }\n",
    "\n",
    "    def relevance(self, X, y):\n",
    "        SSE = np.sum(np.square(y - X @ self.b))\n",
    "        SST = np.sum(np.square(y - np.mean(y)))\n",
    "        SSR = SST - SSE\n",
    "        R_squared = SSR / SST\n",
    "        return R_squared\n",
    "    \n",
    "    def test_relevance(self, X, y):\n",
    "        SSE = np.sum(np.square(y - X @ self.b))\n",
    "        RSE = np.sqrt(SSE / (self._n - 2))\n",
    "        MSE = (1 / self._n) * SSE\n",
    "        RMSE = np.sqrt(MSE)\n",
    "        return {\n",
    "            \"RSE\": RSE,\n",
    "            \"MSE\": MSE, \n",
    "            \"RMSE\": RMSE\n",
    "        }\n",
    "\n",
    "    def pearson(self, X, y):\n",
    "        kin_geo = stats.pearsonr(X[:,1], X[:,2])\n",
    "        kin_ine = stats.pearsonr(X[:,1], X[:,3])\n",
    "        geo_ine = stats.pearsonr(X[:,2], X[:,3])\n",
    "        return {\n",
    "            \"kin_geo\": kin_geo,\n",
    "            \"kin_ine\": kin_ine,\n",
    "            \"geo_ine\": geo_ine\n",
    "        }\n",
    "    \n",
    "    def confidence_intervals(self, X, y):\n",
    "        var = self.variance(X, y)\n",
    "        std_dev = self.standard_deviation(X, y)\n",
    "        cov_matrix = np.linalg.pinv(X.T @ X) * var\n",
    "        t_crit = stats.t.ppf(1 - self.a / 2, self._n - self._d - 1)\n",
    "        intervals = []\n",
    "        for i in range(self._d + 1):\n",
    "            margin = t_crit * std_dev * np.sqrt(cov_matrix[i,i])\n",
    "            lower = self.b[i] - margin\n",
    "            upper = self.b[i] + margin\n",
    "            intervals.append((lower, upper))\n",
    "        return intervals\n",
    "    \n",
    "    def observer_bias(self, X, y):\n",
    "        \"\"\"\n",
    "        Test significance on the observer values. \n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n",
      "Number of rows: 118\n",
      "Variance: 2.96e-03\n",
      "Standard deviation: 5.44e-02\n",
      "Significance of f-statistic: 3.93e-143\n",
      "Significance of t-statistic for ...\n",
      "... Kinematic: 1.75e-75\n",
      "... Geometric: 3.60e-157\n",
      "... Inertial: 2.06e-245\n",
      "Relevance (R²): 9.97e-01\n",
      "Training relevance ...\n",
      "... RSE: 5.37e-02\n",
      "... MSE: 2.84e-03\n",
      "... RMSE:  5.32e-02\n",
      "Validation relevance ...\n",
      "... RSE: 3.19e-02\n",
      "... MSE: 9.99e-04\n",
      "... RMSE:  3.16e-02\n",
      "Kinematic - Geometric: 8.69e-01 (correlation), 3.34e-37 (p-value)\n",
      "Kinematic - Inertial: 9.72e-01 (correlation), 7.72e-75 (p-value)\n",
      "Geometric - Inertial: 9.20e-01 (correlation), 6.91e-49 (p-value)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "# from linear_regression import LinearRegression as lr\n",
    "\n",
    "# Importing and standardising data\n",
    "\n",
    "data = pd.read_csv(\"../data/Small-diameter-flow.csv\", index_col=0)\n",
    "data_std = data.copy()\n",
    "for column in [\"Flow\", \"Kinematic\", \"Geometric\", \"Inertial\"]:\n",
    "    mean = np.mean(data[column])\n",
    "    sample_std_dev = np.std(data[column], ddof=1)\n",
    "    data_std[column] = (data[column] - mean) / sample_std_dev\n",
    "data_std\n",
    "\n",
    "# Creating sets\n",
    "\n",
    "data_shuffled = data_std.sample(frac=1, random_state=42)  # setting the seed for reproducibility\n",
    "\n",
    "train_indices = round(0.8 * len(data_shuffled))\n",
    "val_indices = round(0.25 * train_indices)\n",
    "test_indices = round(0.2 * len(data_shuffled))\n",
    "\n",
    "test_df = pd.DataFrame(data_shuffled[:test_indices])\n",
    "train_df = pd.DataFrame(data_shuffled[test_indices:])\n",
    "val_df = pd.DataFrame(train_df[:val_indices])\n",
    "train_df = pd.DataFrame(train_df[val_indices:])\n",
    "\n",
    "X_train = np.column_stack([np.ones(len(train_df)), train_df[\"Kinematic\"], train_df[\"Geometric\"], train_df[\"Inertial\"], train_df[\"Observer\"]])\n",
    "y_train = train_df[\"Flow\"]\n",
    "\n",
    "X_val = np.column_stack([np.ones(len(val_df)), val_df[\"Kinematic\"], val_df[\"Geometric\"], val_df[\"Inertial\"], val_df[\"Observer\"]])\n",
    "y_val = val_df[\"Flow\"]\n",
    "\n",
    "X_test = np.column_stack([np.ones(len(test_df)), test_df[\"Kinematic\"], test_df[\"Geometric\"], test_df[\"Inertial\"], test_df[\"Observer\"]])\n",
    "y_test = test_df[\"Flow\"]\n",
    "\n",
    "\n",
    "# Running the model\n",
    "\n",
    "model = lr()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "print(f\"Number of features: {model.d}\")\n",
    "print(f\"Number of rows: {model.n}\")     # from X_train\n",
    "print(f\"Variance: {model.variance(X_train, y_train):.2e}\")\n",
    "print(f\"Standard deviation: {model.standard_deviation(X_train, y_train):.2e}\")\n",
    "\n",
    "# returns dictionary with f_pvalue and ti_pvalues\n",
    "sig = model.significance(X_train, y_train)\n",
    "print(f\"Significance of f-statistic: {sig[\"f_pvalue\"]:.2e}\")\n",
    "print(f\"Significance of t-statistic for ...\\n... Kinematic: {sig[\"ti_pvalues\"][0]:.2e}\\n... Geometric: {sig[\"ti_pvalues\"][1]:.2e}\\n... Inertial: {sig[\"ti_pvalues\"][2]:.2e}\")\n",
    "\n",
    "print(f\"Relevance (R²): {model.relevance(X_train, y_train):.2e}\")\n",
    "\n",
    "# returns dictionary with RSE, MSE and RMSE\n",
    "t_rel = model.test_relevance(X_train, y_train)\n",
    "v_rel = model.test_relevance(X_val, y_val)\n",
    "t_rel = {key: value.item() for key, value in t_rel.items()}\n",
    "v_rel = {key: value.item() for key, value in v_rel.items()}\n",
    "print(f\"Training relevance ...\\n... RSE: {t_rel[\"RSE\"]:.2e}\\n... MSE: {t_rel[\"MSE\"]:.2e}\\n... RMSE:  {t_rel[\"RMSE\"]:.2e}\")\n",
    "print(f\"Validation relevance ...\\n... RSE: {v_rel[\"RSE\"]:.2e}\\n... MSE: {v_rel[\"MSE\"]:.2e}\\n... RMSE:  {v_rel[\"RMSE\"]:.2e}\")\n",
    "\n",
    "# returns Pearson dictionary\n",
    "r = model.pearson(X_train, y_train)\n",
    "print(f\"Kinematic - Geometric: {r[\"kin_geo\"][0]:.2e} (correlation), {r[\"kin_geo\"][1]:.2e} (p-value)\")\n",
    "print(f\"Kinematic - Inertial: {r[\"kin_ine\"][0]:.2e} (correlation), {r[\"kin_ine\"][1]:.2e} (p-value)\")\n",
    "print(f\"Geometric - Inertial: {r[\"geo_ine\"][0]:.2e} (correlation), {r[\"geo_ine\"][1]:.2e} (p-value)\")\n",
    "\n",
    "## returns the confidence intervals for all parameters\n",
    "# ci = model.confidence_intervals(X_train, y_train)\n",
    "# for i, interval in enumerate(ci):\n",
    "#     print(f\"Confidence interval on predictor β1: {ci[0]:.4f} ± {ci[1]:.4f} interval: [{ci[0]- ci[1]:.3f}, {ci[0]+ ci[1]:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konfidensintervall - lös direkt i metoden att returlistan ser ut som βi ± value\n",
    "# kolla signifikansen på båda observers för sista VG-frågan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence intervals for each parameter:\n",
      "β_0: -0.0175 ± 0.0007\n",
      "β_1: 0.2968 ± 0.0023\n",
      "β_2: 1.1006 ± 0.0014\n",
      "β_3: -0.3989 ± 0.0029\n",
      "β_4: 0.0191 ± 0.0011\n"
     ]
    }
   ],
   "source": [
    "var = model.variance(X_train, y_train)\n",
    "std_dev = model.standard_deviation(X_train, y_train)\n",
    "cov_matrix = np.linalg.pinv(X_train.T @ X_train) * var\n",
    "\n",
    "# Extract the diagonal elements of the covariance matrix\n",
    "C_ii = np.diag(cov_matrix)\n",
    "\n",
    "# Calculate the critical value t_{alpha / 2}\n",
    "alpha = 0.05\n",
    "degrees_of_freedom = model.n - model.d - 1\n",
    "t_value = stats.t.ppf(1 - alpha / 2, degrees_of_freedom)\n",
    "\n",
    "# Compute the margin of error for each parameter\n",
    "margin_of_error = t_value * std_dev * np.sqrt(C_ii)\n",
    "\n",
    "# Calculate the confidence interval for each parameter\n",
    "confidence_intervals = [(model.b[i] - margin_of_error[i], model.b[i] + margin_of_error[i]) for i in range(len(model.b))]\n",
    "\n",
    "print(\"Confidence intervals for each parameter:\")\n",
    "for i, ci in enumerate(confidence_intervals):\n",
    "    margin = (ci[1] - ci[0]) / 2\n",
    "    print(f\"β_{i}: {model.b[i]:.4f} ± {margin:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β_0: -0.0175 ± 0.0007\n",
      "β_1: 0.2968 ± 0.0023\n",
      "β_2: 1.1006 ± 0.0014\n",
      "β_3: -0.3989 ± 0.0029\n",
      "β_4: 0.0191 ± 0.0011\n"
     ]
    }
   ],
   "source": [
    "ival = model.confidence_intervals(X_train, y_train)\n",
    "for i, (lower, upper) in enumerate(ival):\n",
    "    margin = (upper - lower) / 2\n",
    "    print(f\"β_{i}: {model.b[i]:.4f} ± {margin:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Har frågat Raphael om detta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syy: 119.14909480499718\n",
      "TSS: 119.14909480499716\n",
      "\n",
      "Sxx1: 309.7393883916007\n",
      "Sxx2: 2.6473451999282114\n",
      "SSX: 495.83172641397806\n",
      "ISLP: 4.237878003538274\n"
     ]
    }
   ],
   "source": [
    "Syy = (n * np.sum(np.square(y_train)) - np.square(np.sum(y_train))) / n             # från Raphaels code-along\n",
    "TSS = np.sum(np.square(y_train - np.mean(y_train)))                                 # från andra källor\n",
    "\n",
    "Sxx1 = (n * np.sum(np.square(X_train)) - np.square(np.sum(X_train))) / n            # från Raphaels code-along\n",
    "Sxx2 = (n * np.sum(np.square(X_train)) - np.square(np.sum(X_train))) / (n * (n-1))  # från handledning\n",
    "SSX = np.sum(np.square(X_train - np.mean(X_train)))                                 # från andra källor\n",
    "\n",
    "Sxx_ISLP = np.sum(np.square(X_train - np.mean(X_train))) / (n - 1)  # page 183 in ISLP\n",
    "\n",
    "print(f\"Syy: {Syy}\\nTSS: {TSS}\")\n",
    "print()\n",
    "print(f\"Sxx1: {Sxx1}\\nSxx2: {Sxx2}\\nSSX: {SSX}\")\n",
    "print(f\"ISLP: {Sxx_ISLP}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
