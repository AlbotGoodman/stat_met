{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the pipe flow data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will statistically explore the pipe flow data set and try to implement a predictive regression model. There are tried and trued modules for this but since they lack rigoruous statistical comparison I will write these from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from linear_regression import LinearRegression as lr\n",
    "\n",
    "data = pd.read_csv(\"../data/Small-diameter-flow.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffled = data.sample(frac=1, random_state=42)  # setting the seed for reproducibility\n",
    "\n",
    "train_indices = round(0.8 * len(data_shuffled))\n",
    "val_indices = round(0.25 * train_indices)\n",
    "test_indices = round(0.2 * len(data_shuffled))\n",
    "\n",
    "test_df = pd.DataFrame(data_shuffled[:test_indices])\n",
    "train_df = pd.DataFrame(data_shuffled[test_indices:])\n",
    "val_df = pd.DataFrame(train_df[:val_indices])\n",
    "train_df = pd.DataFrame(train_df[val_indices:])\n",
    "\n",
    "X_train = np.column_stack([np.ones(len(train_df)), train_df[\"Kinematic\"], train_df[\"Geometric\"], train_df[\"Inertial\"], train_df[\"Observer\"]])\n",
    "y_train = train_df[\"Flow\"]\n",
    "\n",
    "X_val = np.column_stack([np.ones(len(val_df)), val_df[\"Kinematic\"], val_df[\"Geometric\"], val_df[\"Inertial\"], val_df[\"Observer\"]])\n",
    "y_val = val_df[\"Flow\"]\n",
    "\n",
    "X_test = np.column_stack([np.ones(len(test_df)), test_df[\"Kinematic\"], test_df[\"Geometric\"], test_df[\"Inertial\"], test_df[\"Observer\"]])\n",
    "y_test = test_df[\"Flow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As necessary for a predictive model I split the available data into set. I've used the 80/20 rule of thumb and used 80 % of the data towards training and 20 % to testing. I have also split the training data further into a validation set as well. Splitting that into 75/25 I have ensured that the size of the validation set match the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 118\n",
      "Validation set size: 40\n",
      "Test set size: 40\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = lr.standardise(X_train, True)\n",
    "y_train = lr.standardise(y_train, False)\n",
    "\n",
    "X_val = lr.standardise(X_val, True)\n",
    "y_val = lr.standardise(y_val, False)\n",
    "\n",
    "X_test = lr.standardise(X_test, True)\n",
    "y_test = lr.standardise(y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I do here is to set the mean and standard deviation of each feature to practically zero and one, respectively. I do so to make sure that all features are on the same scale. That would perhaps not be necessary in this case, let's look at the minimum and maximum values of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow\n",
      "Max value: -11.095608576515785\n",
      "Min value: -17.04768667660043\n",
      "\n",
      "Kinematic\n",
      "Max value: 1.242506468328179\n",
      "Min value: -0.6988778552689303\n",
      "\n",
      "Geometric\n",
      "Max value: -5.069475794119189\n",
      "Min value: -6.8963265831585145\n",
      "\n",
      "Inertial\n",
      "Max value: -11.583284099183867\n",
      "Min value: -14.332156294806332\n",
      "\n",
      "Observer\n",
      "Max value: 1.0\n",
      "Min value: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in data.columns:\n",
    "    print(f\"{feature}\\nMax value: {data[feature].max()}\\nMin value: {data[feature].min()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values differ from each other but not in extremes. Still, the max value of inertial is ten times that of kinematic. Therefore I have chosen to standardise the data to more fairly evaluate them. That is also why I have not normalised the data, as to keep the shape of the data.   \n",
    "\n",
    "What I would do differently next time is to fully implement this in the LinearRegression class. Then I could do the standardising in other methods and also save the mean and standard deviation from the training set to use in the other sets to avoid data leakage and always evaluate against the training values. Keep this in mind as we digest the significance and relevance later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance of f-statistic: 3.93e-143\n",
      "Significance of t-statistic for ...\n",
      "... Kinematic: 2.68e-45\n",
      "... Geometric: 1.29e-157\n",
      "... Inertial:  7.37e-246\n",
      "... Observer:  5.71e-161\n",
      "\n",
      "Relevance (R²): 9.97e-01\n",
      "\n",
      "Training relevance ...\n",
      "... RSE:  5.32e-02\n",
      "... MSE:  2.78e-03\n",
      "... RMSE: 5.28e-02\n",
      "\n",
      "Validation relevance ...\n",
      "... RSE:  5.43e-02\n",
      "... MSE:  2.81e-03\n",
      "... RMSE: 5.30e-02\n",
      "\n",
      "Test relevance ...\n",
      "... RSE:  5.01e-02\n",
      "... MSE:  2.38e-03\n",
      "... RMSE: 4.88e-02\n",
      "\n",
      "Confidence intervals for each coefficient ...\n",
      "... β0: -0.0087 ± 0.0007 | Lower: -0.0094, Upper: -0.0079\n",
      "... β1: 0.3028 ± 0.0024 | Lower: 0.3004, Upper: 0.3051\n",
      "... β2: 1.1073 ± 0.0014 | Lower: 1.1058, Upper: 1.1087\n",
      "... β3: -0.4096 ± 0.0030 | Lower: -0.4126, Upper: -0.4066\n",
      "... β4: 0.0189 ± 0.0011 | Lower: 0.0178, Upper: 0.0200\n",
      "\n",
      "Correlation pairs ...\n",
      "... Kinematic - Geometric: 0.8688\n",
      "... Kinematic - Inertial: 0.9720\n",
      "... Kinematic - Observer: 0.1783\n",
      "... Geometric - Inertial: 0.9196\n",
      "... Geometric - Observer: 0.2242\n",
      "... Inertial - Observer: 0.1774\n"
     ]
    }
   ],
   "source": [
    "model = lr()\n",
    "model.fit(X_train, y_train)\n",
    "y_hat_val = model.predict(X_val)\n",
    "\n",
    "sig = model.significance(X_train, y_train) # returns dictionary with f_pvalue and ti_pvalues\n",
    "print(f\"Significance of f-statistic: {sig[\"f_pvalue\"]:.2e}\")\n",
    "print(f\"Significance of t-statistic for ...\\n... Kinematic: {sig[\"ti_pvalues\"][0]:.2e}\\n... Geometric: {sig[\"ti_pvalues\"][1]:.2e}\\n... Inertial:  {sig[\"ti_pvalues\"][2]:.2e}\\n... Observer:  {sig[\"ti_pvalues\"][3]:.2e}\")\n",
    "print()\n",
    "print(f\"Relevance (R²): {model.r_squared(X_train, y_train):.2e}\")\n",
    "print()\n",
    "\n",
    "train_rel = model.relevance(X_train, y_train) # returns dictionary with RSE, MSE and RMSE\n",
    "val_rel = model.relevance(X_val, y_val)\n",
    "test_rel = model.relevance(X_test, y_test)\n",
    "train_rel = {key: value.item() for key, value in train_rel.items()}\n",
    "val_rel = {key: value.item() for key, value in val_rel.items()}\n",
    "test_rel = {key: value.item() for key, value in test_rel.items()}\n",
    "print(f\"Training relevance ...\\n... RSE:  {train_rel[\"RSE\"]:.2e}\\n... MSE:  {train_rel[\"MSE\"]:.2e}\\n... RMSE: {train_rel[\"RMSE\"]:.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Validation relevance ...\\n... RSE:  {val_rel[\"RSE\"]:.2e}\\n... MSE:  {val_rel[\"MSE\"]:.2e}\\n... RMSE: {val_rel[\"RMSE\"]:.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Test relevance ...\\n... RSE:  {test_rel[\"RSE\"]:.2e}\\n... MSE:  {test_rel[\"MSE\"]:.2e}\\n... RMSE: {test_rel[\"RMSE\"]:.2e}\")\n",
    "print()\n",
    "\n",
    "ci = model.confidence_intervals(X_train, y_train) # returns the confidence intervals for all parameters\n",
    "print(\"Confidence intervals for each coefficient ...\")\n",
    "for i, margin in enumerate(ci):\n",
    "    print(f\"... β{i}: {model._b[i]:.4f} ± {margin:.4f} | Lower: {model._b[i] - margin:.4f}, Upper: {model._b[i] + margin:.4f}\")\n",
    "print()\n",
    "\n",
    "r = model.pearson(X_train) # returns a correlation matrix\n",
    "cols = [\"Kinematic\", \"Geometric\", \"Inertial\", \"Observer\"]\n",
    "print(\"Correlation pairs ...\")\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        print(f\"... {cols[i]} - {cols[j]}: {r[i, j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the output\n",
    "\n",
    "We can tell from the extremely low p-values that the significance of the regression as a whole and each parameter is highly significant. What that means is that the probability of the null hypothesis being true is very, very low. If there was no relationship between the model (or the features) the probability would instead have been high. All features contribute to predict flow values. There is however one parameter that sticks out and that is kinematic. It has the lowest (comparably) significance out of all. What could be interesting is to exclude that in another run and see what values we would get.  \n",
    "\n",
    "R² tells us that the model has an excellent fit. We can predict 99.7 % of the data using our dependant variables. Since we now know that the significance of those variables are also relevant we can conclude that the high result in R² is not just a fluke. However further analysis could be appropriate to investigate overfitting or if the relationship between the variables causes this.  \n",
    "\n",
    "Regarding relevance we have a few interesting results. Generally we would hope that the values would be lower in the validation and testing. Here they do not which could just be the result of the shuffled data but also the +not fully correct implementation of standardisation. Despite that though the intervals are not big which speaks in favour of a more stable model.  \n",
    "\n",
    "Speaking of narrow intervals, we can see the same in the confidence intervals. With our 95 % confidence level we can be 95 % sure that the true values would lie between these narrow intervals. Depending on the need of the regression model this could be either very good or not even functional. Typically scientific accuracy need slim margins while perhaps a commercial model more uncertainty would be accepted.  \n",
    "\n",
    "Lastly we look at the intervals. Immediately we find that all parameters correlate highly with each other, something we call multicollinearity. It means that ... and can lead to unreliable estimates on unseen data. Preferrably we would remove variables that show high correlation between each other or increase the data - which is not plausible in this case.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating observer bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my understanding there is an observer bias in the data and I will briefly discuss this below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4393939393939394\n"
     ]
    }
   ],
   "source": [
    "# more values were recorded by observer 0\n",
    "mean_obs = data[\"Observer\"].mean()\n",
    "print(mean_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the mean value of the entire data set the value is below 0.5 indicating that more measurements were provided by the observer categorically and binary named 0 in this set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# higher values were recorded by observer 1\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(data=data, x=\"Observer\", y=\"Flow\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can also tell that the fewer (as stated above) measurements recorded by observer 1 also tend to be of a higher value with far less spread among outliers.  \n",
    "\n",
    "I also want to highlight a few other arguments for observer bias. The p-value of the observer is 5.71e-161 (on par with the geometric variable). This suggest that the observer has an effect on the predicted flow. This is the main reason as to how we can statistically show that the null hypothesis for the observer variable is rejected. On the other hand the Pearson r-value is never above 0.23 indicating low correlation. This could indicate that the observer might not have a meaningful impact on the measurements in the data set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "Spoiler alert: the data set has been collected by the teacher in this course. And as has been mentioned during lectures the reason that the relationship between the features is so strong is due to them being fundamental in fluid dynamics.  \n",
    "\n",
    "That is why our model can show such high values in R² and the relevance between sets be so static. However it has still been a challenge to correctly performing a \"statistical analysis\", meaning implementing tools to measure and evaluate the model.  \n",
    "\n",
    "I have also enjoyed the opportunity to try my hands on a predictive model and look forward to learning more about machine learning techniques.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
